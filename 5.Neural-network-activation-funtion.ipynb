{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9b078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nnfs in /usr/local/lib/python3.12/dist-packages (0.5.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from nnfs) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nnfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb0df26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.        ]\n",
      " [ 0.00010155  0.0002542  -0.00011534]\n",
      " [ 0.00019088  0.00044682 -0.00012087]\n",
      " [ 0.0002709   0.00061784 -0.00012105]\n",
      " [ 0.00039125  0.00101733 -0.00056212]]\n"
     ]
    }
   ],
   "source": [
    "## Dence layer class \n",
    "\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "\n",
    "\n",
    "class Layer_Dense:\n",
    "    # layer initialization \n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        # initialize weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs,n_neurons)\n",
    "        # initialize biases 0\n",
    "        self.biases = np.zeros([1,n_neurons])\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        # forward pass\n",
    "        self.outputs = np.dot(inputs,self.weights) + self.biases\n",
    "\n",
    "X , y = spiral_data(samples=100,classes=3)\n",
    "\n",
    "dense1 = Layer_Dense(n_inputs=2,n_neurons=3)\n",
    "\n",
    "dense1.forward(X)\n",
    "\n",
    "dense1.forward(X)\n",
    "\n",
    "print(dense1.outputs[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962a1c1",
   "metadata": {},
   "source": [
    "#### **Implements of the ReLU and Sigmoid functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1568460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  2.  0.  3.3 0.  1.1 2.2 0. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "inputs  = [0,2,-1,3.3,-2.7,1.1,2.2,-100]\n",
    "\n",
    "outputs = np.maximum(0,inputs)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ca960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Activation function class\n",
    "\n",
    "class Activation_ReLU:\n",
    "    def forward(self,inputs):\n",
    "        self.outputs = np.maximum(0,inputs)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a36b2ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06414769 0.17437149 0.47399085 0.28748998]\n",
      " [0.07839412 0.2130973  0.57925853 0.12925005]\n",
      " [0.08536889 0.23205671 0.63079554 0.05177885]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [[1,2,3,2.5],\n",
    "          [2,3,4,2.5],\n",
    "          [3,4,5,2.5]]\n",
    "\n",
    "# get unnormalized probability\n",
    "exp_value = np.exp(inputs - np.max(inputs , axis = 1 , keepdims = True))\n",
    "\n",
    "# get normalized probability\n",
    "normalized_prob = exp_value / np.sum(exp_value , axis = 1 , keepdims = True)\n",
    "\n",
    "print(normalized_prob)\n",
    "\n",
    "np.sum(normalized_prob , axis = 1 , keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b89748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax class\n",
    "class Activation_Softmax:\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # get unnormalized probability\n",
    "        exp_value = np.exp(inputs - np.max(inputs , axis = 1 , keepdims = True))\n",
    "\n",
    "# get normalized probability\n",
    "        normalized_prob = exp_value / np.sum(exp_value , axis = 1 , keepdims = True)\n",
    "\n",
    "        self.output = normalized_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55336dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333405 0.33333261 0.33333333]\n",
      " [0.33333413 0.33333295 0.33333292]\n",
      " [0.33333417 0.33333327 0.33333256]\n",
      " [0.3333334  0.33333352 0.33333308]]\n"
     ]
    }
   ],
   "source": [
    "X ,y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "\n",
    "activation2 = Activation_Softmax()\n",
    "\n",
    "\n",
    "# create Dense layer with 2 inputs and 3 output values \n",
    "\n",
    "dense1 = Layer_Dense(2 , 3)\n",
    "\n",
    "dense1.forward(X)\n",
    "\n",
    "activation1.forward(dense1.outputs)\n",
    "\n",
    "dense2 = Layer_Dense(3, 3)\n",
    "\n",
    "dense2.forward(activation1.outputs)\n",
    "\n",
    "activation2.forward(dense2.outputs)\n",
    "\n",
    "print(activation2.output[:5])\n",
    "\n",
    "\n",
    "\n",
    "# create ReLu activation function on dencse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35deba0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
